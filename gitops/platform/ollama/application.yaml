apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/otwld/ollama-helm
    targetRevision: 0.1.x
    chart: ollama
    helm:
      values: |
        ollama:
          models:
            - llama3
        nodeSelector:
          pool: worker-high
        resources:
          limits:
            cpu: "4"
            memory: 8Gi
  destination:
    server: https://kubernetes.default.svc
    namespace: ai-inference
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
